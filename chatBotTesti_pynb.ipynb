{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNiwY0sLkucgY+KOYkssXnW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SoumadeepMandal/Smart_chatbot/blob/main/chatBotTesti_pynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install newspaper3k lxml[html_clean]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRKQuljq7KM9",
        "outputId": "78c4d903-950f-4722-e5cc-977460da41e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting newspaper3k\n",
            "  Downloading newspaper3k-0.2.8-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: lxml[html_clean] in /usr/local/lib/python3.11/dist-packages (5.4.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (4.13.4)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (11.2.1)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (6.0.2)\n",
            "Collecting cssselect>=0.9.2 (from newspaper3k)\n",
            "  Downloading cssselect-1.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (3.9.1)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (2.32.3)\n",
            "Collecting feedparser>=5.2.1 (from newspaper3k)\n",
            "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting tldextract>=2.0.1 (from newspaper3k)\n",
            "  Downloading tldextract-5.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting feedfinder2>=0.0.4 (from newspaper3k)\n",
            "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jieba3k>=0.35.1 (from newspaper3k)\n",
            "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (2.9.0.post0)\n",
            "Collecting tinysegmenter==0.3 (from newspaper3k)\n",
            "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lxml_html_clean (from lxml[html_clean])\n",
            "  Downloading lxml_html_clean-0.4.2-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (4.13.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.17.0)\n",
            "Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2.1->newspaper3k) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2.1->newspaper3k) (1.5.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2.1->newspaper3k) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2.1->newspaper3k) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.10.0->newspaper3k) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.10.0->newspaper3k) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.10.0->newspaper3k) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.10.0->newspaper3k) (2025.4.26)\n",
            "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k)\n",
            "  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.11/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.18.0)\n",
            "Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cssselect-1.3.0-py3-none-any.whl (18 kB)\n",
            "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tldextract-5.3.0-py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.4/107.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lxml_html_clean-0.4.2-py3-none-any.whl (14 kB)\n",
            "Downloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Building wheels for collected packages: tinysegmenter, feedfinder2, jieba3k, sgmllib3k\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13540 sha256=71c4ce976c5097a641bb4598660135e881077d97bba32f583af57046f3c20ad1\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/f8/cce3a9ae6d828bd346be695f7ff54612cd22b7cbd7208d68f3\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3341 sha256=1820034c90f8ccfb4bd1a779f62a11db7990b737db9bb48e9fb2e99d15c972a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/d5/72/9cd9eccc819636436c6a6e59c22a0fb1ec167beef141f56491\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398380 sha256=019b051e4fc5c5fd217ca4af4d24627a64429a45fa0c24a7c1c44e06dd804a21\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/a1/46/8e68055c1713f9c4598774c15ad0541f26d5425ee7423b6493\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=561625bdafeb90e7986f66a600bf1a2973cb44a229645b0fdafc22a0e6537445\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/25/2a/105d6a15df6914f4d15047691c6c28f9052cc1173e40285d03\n",
            "Successfully built tinysegmenter feedfinder2 jieba3k sgmllib3k\n",
            "Installing collected packages: tinysegmenter, sgmllib3k, jieba3k, lxml_html_clean, feedparser, cssselect, requests-file, feedfinder2, tldextract, newspaper3k\n",
            "Successfully installed cssselect-1.3.0 feedfinder2-0.0.4 feedparser-6.0.11 jieba3k-0.35.1 lxml_html_clean-0.4.2 newspaper3k-0.2.8 requests-file-2.1.0 sgmllib3k-1.0.0 tinysegmenter-0.3 tldextract-5.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import nltk\n",
        "import numpy as np\n",
        "from newspaper import Article\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import warnings\n"
      ],
      "metadata": {
        "id": "Ikk90gpk7hQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "aa-24oK47VdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "varOcg = \"chronic kidney disease expert assistant\""
      ],
      "metadata": {
        "id": "xglP-O9s70hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "# Download the punkt_tab resource which might be required by newspaper's nlp()\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def normalize(text):\n",
        "    tokens = nltk.word_tokenize(text.lower())\n",
        "    return ' '.join([lemmatizer.lemmatize(token) for token in tokens])\n",
        "\n",
        "url = 'https://en.wikipedia.org/wiki/Kidney_disease'\n",
        "article = Article(url)\n",
        "article.download()\n",
        "article.parse()\n",
        "article.nlp()\n",
        "corpus = article.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifAtDVTM76i0",
        "outputId": "005453cb-eea1-40f9-eaea-9910586bf6db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_list = nltk.sent_tokenize(corpus)"
      ],
      "metadata": {
        "id": "5b248JwS9h6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_greetings = ['hi', 'hello', 'hey', 'whatsup', 'howdy', 'hola']\n",
        "bot_greetings = ['Hello!', 'Hi there!', 'Hey!', 'Howdy!', 'Greetings!']\n",
        "\n",
        "def greeting_response(text):\n",
        "    for word in text.lower().split():\n",
        "        if word in user_greetings:\n",
        "            return random.choice(bot_greetings)\n",
        "    return None"
      ],
      "metadata": {
        "id": "VqHIEdWq9l4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exit_list = ['exit', 'bye', 'see you', 'break', 'quit']"
      ],
      "metadata": {
        "id": "cK0kr_Vy9pfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fallbacks = [\n",
        "    \"I'm not sure I understand. Could you rephrase?\",\n",
        "    \"Sorry, I didn't catch that. Ask something else about kidney disease.\",\n",
        "    \"I can help with symptoms, causes, or treatment. Try asking something specific.\"\n",
        "]"
      ],
      "metadata": {
        "id": "S5g2NfE39xol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bot_response(user_input):\n",
        "    user_input = normalize(user_input)\n",
        "    sentence_list.append(user_input)\n",
        "\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(sentence_list)\n",
        "    similarity_scores = cosine_similarity(tfidf_matrix[-1], tfidf_matrix)\n",
        "    similarity_scores_list = similarity_scores.flatten()\n",
        "    index_scores = similarity_scores_list.argsort()[::-1]\n",
        "\n",
        "    response = ''\n",
        "    response_found = False\n",
        "    added = 0\n",
        "\n",
        "    for index in index_scores:\n",
        "        if index != len(sentence_list) - 1 and similarity_scores_list[index] > 0:\n",
        "            response += sentence_list[index] + ' '\n",
        "            response_found = True\n",
        "            added += 1\n",
        "        if added >= 2:\n",
        "            break\n",
        "\n",
        "    sentence_list.pop()\n",
        "\n",
        "    if not response_found:\n",
        "        return random.choice(fallbacks)\n",
        "    return response.strip()\n"
      ],
      "metadata": {
        "id": "8e2VtRTU92IN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Doc 🤖: Hi! I'm your health assistant. Ask me anything about chronic kidney disease. Type 'exit' to leave.\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if any(exit_word in user_input.lower() for exit_word in exit_list):\n",
        "        print(\"Doc 🤖: Bye! Take care.\")\n",
        "        break\n",
        "    elif greeting_response(user_input):\n",
        "        print(\"Doc 🤖:\", greeting_response(user_input))\n",
        "    else:\n",
        "        print(\"Doc 🤖:\", bot_response(user_input))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrWOcDsJ98BV",
        "outputId": "1ff8a12e-9d5a-4a57-f646-737d7d54b1a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Doc 🤖: Hi! I'm your health assistant. Ask me anything about chronic kidney disease. Type 'exit' to leave.\n",
            "You: hi\n",
            "Doc 🤖: Hi there!\n",
            "You: what is Kidney disease?\n",
            "Doc 🤖: Nephrosis is non-inflammatory kidney disease. COVID-19 is associated with kidney disease.\n",
            "You: be more secific  \n",
            "Doc 🤖: [11] This may be because sources of animal protein, animal fat, and cholesterol, and sweets are more acid-producing, while fruits, vegetables, legumes, and whole grains are more base-producing. Chronic kidney disease is defined as prolonged kidney abnormalities (functional and/or structural in nature) that last for more than three months.\n",
            "You: what are the risk?\n",
            "Doc 🤖: Currently, the underlying mechanisms are unclear. Polycystic kidneys are susceptible to infections and cancer.\n",
            "You: what are the factors of this ?\n",
            "Doc 🤖: \"[8] The same article also goes on to say that millions of Americans are affected by this disease and it is very common. [11] This may be because sources of animal protein, animal fat, and cholesterol, and sweets are more acid-producing, while fruits, vegetables, legumes, and whole grains are more base-producing.\n",
            "You: bye\n",
            "Doc 🤖: Bye! Take care.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "S0SiZvHmIiaT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}